{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Order Predicitve modeling\n",
    "\n",
    "This notebook demonstrates a step-by-step approach to creating a predictive model for forecasting orders for the month.\n",
    "\n",
    "To guide the solution to the problem, I can start by addressing the following two principal questions:\n",
    "\n",
    "1. What are the expected order days for each client?\n",
    "2. How confident is the model built?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Environment Setup\n",
    "\n",
    "To begin the project, I created a Conda environment named `ps_bee` with Python 3.10. After setting up the environment, I installed the necessary packages listed in the `requirements.txt` file.\n",
    "\n",
    "```bash\n",
    "conda create --name ps_bee python=3.10\n",
    "conda activate ps_bee\n",
    "```\n",
    "\n",
    "The `requirements.txt` file:\n",
    "```text\n",
    "pandas==2.2.2\n",
    "numpy==2.1.0\n",
    "ipykernel==6.29.5\n",
    "pyarrow==17.0.0\n",
    "fastparquet==2024.5.0\n",
    "pandas-profiling==3.6.6\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ydata_profiling import ProfileReport\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection and Preparation\n",
    "\n",
    "This step consists of the **ETL (Extract, Transform, Load)** process for data collection. Here, I prepare the data to be ready for consumption.\n",
    "\n",
    "To assist in this analysis, I used the `pandas-profiling` framework. `pandas-profiling` is a tool that provides an extensive analysis of the data. However, this analysis can make the notebook quite large, so I save the generated report in html files. In this notebook, I am only showing the main insights I have found.\n",
    "\n",
    "The input of this cell is the raw data. The output is the processed data.\n",
    "\n",
    "I created a folder schema like this:\n",
    "```text\n",
    "data/\n",
    "├── raw/\n",
    "│   ├── august_total_sales.parquet\n",
    "│   ├── august_with_missing_order_days.parquet\n",
    "│   └── historical_orders.parquet\n",
    "└── processed/\n",
    "    ├── processed_sales.csv\n",
    "    └── target_processed.csv\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the folders if they don't exist\n",
    "folders = [\n",
    "    \"data/raw\",\n",
    "    \"data/processed\"\n",
    "]\n",
    "\n",
    "for folder in folders:\n",
    "    os.makedirs(folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define functions to ETL data\n",
    "\n",
    "The cell below contain the function created to step of processing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ETL functions\n",
    "def ETL_august_total_sales(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extracts, transforms, and loads data from the specified parquet file.\n",
    "    \n",
    "    :param file_path: Path to the parquet file for August total sales.\n",
    "    :return: DataFrame containing the data from the parquet file.\n",
    "    \"\"\"\n",
    "    df_read = pd.read_parquet(file_path)\n",
    "    return df_read\n",
    "\n",
    "def ETL_august_with_missing_order_days(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extracts, transforms, and loads data from the specified parquet file.\n",
    "    \n",
    "    :param file_path: Path to the parquet file for August with missing order days.\n",
    "    :return: DataFrame containing the data from the parquet file.\n",
    "    \"\"\"\n",
    "    df_read = pd.read_parquet(file_path)\n",
    "    return df_read\n",
    "\n",
    "def ETL_historical_orders(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extracts, transforms, and loads data from the specified parquet file.\n",
    "    \n",
    "    :param file_path: Path to the parquet file for historical orders.\n",
    "    :return: DataFrame containing the data from the parquet file.\n",
    "    \"\"\"\n",
    "    df_read = pd.read_parquet(file_path)\n",
    "    return df_read\n",
    "\n",
    "\n",
    "# Generate profiling reports\n",
    "def generate_profile_report(df: pd.DataFrame, file_name: str):\n",
    "    \"\"\"\n",
    "    Generates a pandas profiling report for the given DataFrame and saves it to an HTML file.\n",
    "    \n",
    "    :param df: DataFrame to profile.\n",
    "    :param file_name: Name of the output HTML file for the profiling report.\n",
    "    \"\"\"\n",
    "    profile = ProfileReport(df, title=file_name, explorative=True)\n",
    "    profile.to_file(file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory paths\n",
    "DIR_AUGUST_TOTAL_SALES = \"data/raw/august_total_sales.parquet\"\n",
    "DIR_AUGUST_WITH_MISSING_ORDER_DAYS = \"data/raw/august_with_missing_order_days.parquet\"\n",
    "DIR_HISTORICAL_ORDERS = \"data/raw/historical_orders.parquet\"\n",
    "\n",
    "\n",
    "# Load the data\n",
    "df_august_total_sales = ETL_august_total_sales(DIR_AUGUST_TOTAL_SALES)\n",
    "df_august_with_missing_order_days = ETL_august_with_missing_order_days(DIR_AUGUST_WITH_MISSING_ORDER_DAYS)\n",
    "df_historical_orders = ETL_historical_orders(DIR_HISTORICAL_ORDERS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below generate an save the report of data using ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset: 100%|██████████| 12/12 [00:04<00:00,  2.85it/s, Completed]                                                              \n",
      "Generate report structure: 100%|██████████| 1/1 [00:12<00:00, 12.17s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:01<00:00,  1.69s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 100.05it/s]\n",
      "Summarize dataset: 100%|██████████| 14/14 [00:13<00:00,  1.00it/s, Completed]                                    \n",
      "Generate report structure: 100%|██████████| 1/1 [00:11<00:00, 11.42s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:02<00:00,  2.12s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 90.95it/s]\n",
      "Summarize dataset: 100%|██████████| 13/13 [03:25<00:00, 15.81s/it, Completed]                                    \n",
      "Generate report structure: 100%|██████████| 1/1 [00:12<00:00, 12.23s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:01<00:00,  1.57s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 90.98it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save the reports\n",
    "generate_profile_report(df_august_total_sales, \"reports/august_total_sales_report.html\")\n",
    "generate_profile_report(df_august_with_missing_order_days, \"reports/august_with_missing_order_days_report.html\")\n",
    "generate_profile_report(df_historical_orders, \"reports/historical_orders_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA - Exploration Data Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ps_bees",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
